---
fontsize: 8pt
bibliography: 7_Referenzen.bib
citation_package: natbib
output:
  beamer_presentation:
    keep_tex: yes
    includes:
      in_header: 7_header.tex
---


```{r, include = F}
source("7_R_common.R")
```

#  {.plain}
\center
```{r, echo = FALSE, out.width = "20%"}
knitr::include_graphics("7_Abbildungen/wtfi_otto.png")
```

\vspace{2mm}

\Huge
Tutorium Allgemeines Lineares Modell
\vspace{2mm}


\normalsize
BSc Psychologie SoSe 2022

\vspace{2mm}
\text{8. Termin (Teil 2): Modellevaluation\_Teil\_1}

\vspace{18mm}
Belinda Fleischmann

\vspace{3mm}
\scriptsize
Inhalte basieren auf [ALM Kursmaterialien](https://www.ipsy.ovgu.de/Institut/Abteilungen+des+Institutes/Methodenlehre+I+_+Experimentelle+und+Neurowissenschaftliche+Psychologie/Lehre/Sommersemester+2022/Allgemeines+Lineares+Modell.html) von [Dirk Ostwald](https://www.ipsy.ovgu.de/Institut/Abteilungen+des+Institutes/Methodenlehre+I+_+Experimentelle+und+Neurowissenschaftliche+Psychologie/Team/Dirk+Ostwald.html), lizenziert unter [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/deed.de)




# Wiederholung - Frequentistisches Weltbild

\vspace{2mm}
```{r, echo = FALSE, out.width = "70%"}
knitr::include_graphics("7_Abbildungen/alm_5_frequentistische_inferenz.pdf")
```


\footnotesize

* Wir nehmen an, dass wahre, aber unbekannte Parameter existieren.
* Wir nehmen weiterhin an, dass probabilistische Prozesse existieren, die, gegeben dieser wahren, aber unbekannten Parameter, Datensätze generieren können. 
* Für diese probabilistischen Prozesse gehen wir davon aus, dass ihnen bestimmte Verteilungen bzw. Wahrscheinlichkeitsdichten zugrundeliegen (z.B. Normalverteilung der Zufallsfehler)
* Wir verwenden erhobene Daten dafür, Parameterwerte zu schätzen (Wir berechnen eine "Einschätzung", was der wahre Wert sein könnte, den wir nicht beobachten können). 
* Dabei bilden die angenommenen Verteilungen bzw. Warhscheinlichkeitsdichten der probabilistischen Prozesse (die, wie wir annehmen, die Daten generiert haben), die Grundlage für Parameterschätzung und Modellevaluation.  



# Wiederholung - Standardannahmen frequentistischer Inferenz
\vspace{1mm}
\footnotesize
\setstretch{1.2}

* Gegeben sei ein statistisches Modell $\mathbb{P}_\theta$, in dem probabilistische Prozesse definiert sind, die Datensätze generieren können. 
* Es wird angenommen, dass ein vorliegender Datensatz eine der möglichen Realisierungen der Daten des Modells ist. Eine mögliche Realisierung wäre $y^{(1)}$,  $y^{(2)}$ wäre eine andere, $y^{(3)}$ wäre nochmals eine andere.
* Aus frequentistischer Sicht kann man unendlich oft Datensätze basierend auf einem Modell generieren und zu jedem Datensatz Schätzer oder Statistiken auswerten, z.B. den Betaparameterschätzer (z.B. $\hat{\beta}^{(1)}$ für Datensatz $y^{(1)}$) 

\scriptsize
\begin{itemize}
\item[] Datensatz (1) : $y^{(1)} = \left(y_1^{(1)}, y_2^{(1)}, ...,y_n^{(1)}\right)^T$  mit $\hat{\beta}^{(1)} = (X^TX)^{-1}X^Ty^{(1)}$
\item[] Datensatz (2) : $y^{(2)} = \left(y_1^{(2)}, y_2^{(2)}, ...,y_n^{(2)}\right)^T$  mit $\hat{\beta}^{(2)} = (X^TX)^{-1}X^Ty^{(2)}$
\item[] Datensatz (3) : $y^{(3)} = \left(y_1^{(3)}, y_2^{(3)}, ...,y_n^{(3)}\right)^T$  mit $\hat{\beta}^{(3)} = (X^TX)^{-1}X^Ty^{(3)}$
\item[] Datensatz (4) : $y^{(4)} = \left(y_1^{(4)}, y_2^{(4)}, ...,y_n^{(4)}\right)^T$  mit $\hat{\beta}^{(4)} = (X^TX)^{-1}X^Ty^{(4)}$
\item[] Datensatz (5) : $y^{(5)} = ...$
\end{itemize}

\footnotesize
\setstretch{1.2}
* Um die Qualität statistischer Methoden zu beurteilen betrachtet die frequentistische Statistik die Wahrscheinlichkeitsverteilungen von Schätzern und Statistiken unter Annahme der Datenverteilung (z.B. im ALM die Verteilung des Datenvektors $y = X \beta + \epsilon$ mit $\epsilon \sim N(0_n, \sigma^2I_n)$, und damit $y\sim N(x\beta,\sigma^2I_n)$, siehe Einheit (5) Theorem zu ALM Datenverteilung). 
* Was ist zum Beispiel die Verteilung (möglicher) Betaparameterschätzer ($\hat{\beta}^{(1)}$, $\hat{\beta}^{(2)}$, $\hat{\beta}^{(3)}$, $\hat{\beta}^{(4)}$), ... also die Verteilung der Zufallsvariable $\hat{\beta} := (X^TX)^{-1}X^Ty$? 



# Selbstkontrollfragen - Modellevaluation

\footnotesize
\setstretch{2}

1. Geben Sie das Theorem zur Frequentistischen Verteilung des Betaparameterschätzers wieder. 
2. Geben Sie die Verteilung des Betaparameterschätzers im Szenarion von $n$ u.i.v. Zufallsvariablen wieder.
3. Geben Sie das Theorem zur Frequentistischen Verteilung des Varianzparameterschätzers wieder.
4. Geben Sie die Verteilung des skalierten Varianzparameterschätzers bei $n$ u.i.v. Zufallsvariablen wieder.
5. Skizzieren Sie die WDFen von $t$-Zufallsvariablen mit $2$, $10$ und $30$ Freiheitsgraden.
6. Skizzieren Sie die WDFen von nichtzentralen $t$-Zufallsvariablen mit Nichtzentralitätsparametern $0$,$5$ und $15$.
7. Geben Sie die Definition der T-Statistik wieder.
8. Erläutern Sie die Definition der T-Statistik.
9. Warum kann die T-Statistik als Signal-zu-Rauschen Verhältnis interpretiert werden.
10. Geben Sie die Form der T-Statistik im Szenario von $n$ u.i.v. Zufallsvariablen wieder.
11. Erläutern Sie den Zusammenhang der T-Statistik und Cohen’s $d$.
12. Geben Sie die Definition der T-Teststatistik wieder.





# Selbstkontrollfragen - Modellevaluation

\footnotesize
\setstretch{2}

13. Erläutern Sie die Definition der T-Teststatistik.
14. Geben Sie das Theorem zur Verteilung der T-Teststatistik wieder.
15. Geben Sie die Definition eines vollständigem und eines reduzierten ALMs wieder.
16. Geben Sie die Definition des Likelihood-Quotienten eines vollständigen und eines reduzierten ALMs wieder.
17. Geben Sie das Theorem zu Likelihood-Quotient und Residualquadratsummendifferenz wieder.
18. Definieren Sie die F-Statistik.
19. Erläutern Sie den Zusammenhang zwischen F-Statistik und Likelihood-Quotient.
20. Definieren Sie und erläutern Sie den Zähler der F-Statistik.
21. Definieren Sie und erläutern Sie den Nenner der F-Statistik.
22. Erläutern Sie die F-Statistik.
23. Geben Sie das Theorem zur Verteilung der F-Statistik wieder.







# Frequentistische Schätzerverteilungen
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 1. Geben Sie das Theorem zur Frequentistischen Verteilung des Betaparameterschätzers wieder. 


\vspace{3mm}
\color{black}

\footnotesize
\begin{theorem}[Frequentistische Verteilung des Betaparameterschätzers]
\justifying
\normalfont
Es sei
\begin{equation}
y = X\beta + \varepsilon \mbox{ mit } \varepsilon \sim N(0_n,\sigma^2I_n)
\end{equation}
das ALM in generativer Form. Weiterhin sei
\begin{equation}
\hat{\beta} = (X^TX)^{-1}X^Ty
\end{equation}
der Betaparameterschätzer. Dann gilt
\begin{equation}
\hat{\beta} \sim N(\beta,\sigma^2(X^T X)^{-1}).
\end{equation}
\end{theorem}

\color{darkcyan}
\footnotesize
Anmerkungen:

* \color{darkcyan}Da es sich bei $\hat{\beta}$ um eine linear-affine Transformation von $y$ handelt, leitet sich die die hier angegeben Verteilung für $\hat{\beta}$ aus dem Theorem zur linearen Transformation von multivariaten Normalverteilung aus Einheit (4) ab. 
* Im Spezifischen besagt das Theorem in diesem Fall, dass wenn $y \sim N(X\beta,\sigma^2I_n)$ und $\hat{\beta}= Ay + b$, dann gilt $\hat{\beta} \sim N(AX\beta+b,A\sigma^2I_nA^T)$, wobei $A=(X^TX)^{-1}X^T$ der Faktor der linearen-affinen Transformation ist.




# Frequentistische Schätzerverteilungen
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 2. Geben Sie die Verteilung des Betaparameterschätzers im Szenario von $n$ u.i.v. Zufallsvariablen wieder.


\vspace{3mm}
\color{black}

\footnotesize
\color{darkcyan}
Das Szenario von $n$ u.i.v. Zufallsvariablen ist in Matrixschreibweise gegeben durch
\begin{align*}
y \sim N(X\beta,\sigma^2 I_n)
\mbox{ mit }
X := 1_n \in \mathbb{R}^{n\times 1},
\beta := \mu \in \mathbb{R}
\mbox{ und } \sigma^2 > 0,
\end{align*}
wobei der Betaparameterschätzer gegeben ist durch $\hat{\beta} = \bar{y}$. Durch Einsetzen von $\beta:=\mu$ und $X:=1_n$ in $\hat{\beta} \sim N(\beta,\sigma^2(X^T X)^{-1})$ (vlg. Theorem zur Frequentistischen Verteilung des Betaparameterschätzers), erhalten wir
\color{black}
\begin{align*}
\bar{y} \sim N\left(\mu, \frac{\sigma^2}{n}\right).
\end{align*}
\color{darkcyan}
Das Stichprobenmittel ($\bar{y}$) von $n$ u.i.v. Zufallsvariablen
mit Erwartungswertparameter $\mu$ und Varianzparameter $\sigma^2$ ist also normalverteilt
mit Erwartungswertparameter $\mu$ und Varianzparameter  $\sigma^2/n$. 



# Frequentistische Schätzerverteilungen
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 2. Geben Sie die Verteilung des Betaparameterschätzers im Szenario von $n$ u.i.v. Zufallsvariablen wieder.

\color{darkcyan}
\footnotesize
Visualisierung von $N\left(\hat{\beta};\beta,\frac{\sigma^2}{n}\right)$ für $y \sim N(X\beta,\sigma^2 I_n)$ mit $\beta = \mu = 2$ und $\sigma^2=1$. Mit anderen Worten, wie sieht die Verteilung der Zufallvariable $\hat{\beta}$ aus, wenn wir aus der von uns angenommenen "wahren" Verteilung des Zufallsvektors $y \sim N(X\beta,\sigma^2 I_n)$ ganz viele Realisierungen generieren, (z.B. 10000 Realisierungen $y^{(1)},...,y^{(10000)}$), und für jede dieser Datensätze einen Betaparameter schätzen ($\hat{\beta}^{(1)}, ..., \hat{\beta}^{(10000)}$). 

\center
\vspace{2mm}
\color{orange}
$N\left(\hat{\beta};\beta,\frac{\sigma^2}{n}\right)$
\vspace{-3mm}
```{r, echo = FALSE, out.width = "50%"}
knitr::include_graphics("7_Abbildungen/alm_7_beta_hat_1.pdf")
```
\vfill






# Frequentistische Schätzerverteilungen
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 3. Geben Sie das Theorem zur Frequentistischen Verteilung des Varianzparameterschätzers wieder.

\vspace{3mm}
\color{black}
\footnotesize

\begin{theorem}[Frequentistische Verteilung des Varianzparameterschätzers]
\normalfont
\justifying
Es sei
\begin{equation}
y = X\beta + \varepsilon \mbox{ mit } \varepsilon \sim N(0_n,\sigma^2I_n)
\end{equation}
das ALM in generative Form. Weiterhin sei
\begin{equation}
\hat{\sigma}^2 = \frac{(y - X\hat{\beta})^T(y - X\hat{\beta})}{n-p}
\end{equation}
der Varianzparameterschätzer. Dann gilt
\begin{equation}
\frac{n-p}{\sigma^2}\hat{\sigma}^2 \sim \chi^2(n-p)
\end{equation}
\end{theorem}






# Frequentistische Schätzerverteilungen
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 4. Geben Sie die Verteilung des skalierten Varianzparameterschätzers bei $n$ u.i.v. Zufallsvariablen wieder.
\vspace{3mm}
\color{black}
\footnotesize

\color{darkcyan}
Wie in Aufg. 2, haben wir im Szenario von $n$ u.i.v. Zufallsvariablen
\begin{align*}
y \sim N(X\beta,\sigma^2 I_n)
\mbox{ mit }
X := 1_n \in \mathbb{R}^{n\times 1},
\beta := \mu \in \mathbb{R}
\mbox{ und } \sigma^2 > 0,
\end{align*}
wobei der Betaparameterschätzer gegeben ist durch $\hat{\beta}=\bar{y}$ und der Varianzparameterschätzer durch $\hat{\sigma}^2=s^2$. 
Durch Einsetzen von $p=1$ in die Verteilung des skalierten Varianzparameterschätzers ($\frac{n-p}{\sigma^2}\hat{\sigma}^2$), wie im Theorem zur Frequentistischen Verteilung des Varianzparamterschätzers gegeben, erhalten wir

\color{black}
\begin{align*}
\frac{n-1}{\sigma^2}\hat{\sigma}^2 \sim \chi^2(n-1)
\end{align*}


\color{darkcyan}
Das ist identisch mit der in Einheit (11) Konfidenzintervalle von  Wahrscheinlichkeitstheorie und Frequentistische Inferenz gelernten U-Statistik. Wdhl.: Für den Fall von $n$ unabhängig und identisch
normalverteilten Zufallsvariablen ist die U-Statistik definiert als
\begin{align*}
U := \frac{n-1}{\sigma^2}s^2,
\end{align*}
wobei
\begin{align*}
U \sim \chi^2(n-1).
\end{align*}
Offenbar ist $U$ für $p = 1$ mit der im obigen Theorem betrachten Zufallsvariable
$\frac{n-p}{\sigma^2}\hat{\sigma}^2$ identisch.



# Frequentistische Schätzerverteilungen
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 4. Geben Sie die Verteilung des skalierten Varianzparameterschätzers bei $n$ u.i.v. Zufallsvariablen wieder.
\vspace{3mm}
\color{black}

```{r, eval=F, echo=F}
# Libraries
library(MASS)                                        # multivariate Normalverteilung
library(matlib)                                      # Matrizenrechnung
library(mvtnorm)

# Modellformulierung
n          = 12                                      # Anzahl von Datenpunkten
p          = 1                                       # Anzahl von Betparametern
X          = matrix(rep(1,n), nrow = n)              # Designmatrix
I_n        = diag(n)                                 # n x n Einheitsmatrix
beta       = 2                                       # wahrer,aber unbekannter,Betaparameter
sigsqr     = 1                                       # wahrer,aber unbekannter,Varianzparameter

# Frequentistische Simulation
nsim       = 1e5                                     # Anzahl Realisierungen n-dimensionaler ZV
beta_hat   = rep(NaN,nsim)                           # \hat{\beta} Realisierungsarray
sigsqr_hat = rep(NaN,nsim)                           # \hat{\sigma}^2 Realisierungsarray
for(i in 1:nsim){
  y             = mvrnorm(1, X %*% beta, sigsqr*I_n) # eine Realisierung n-dimensionaler ZV
  beta_hat[i]   = solve(t(X) %*% X) %*% t(X) %*% y      # \hat{\beta}    = (X^T)X^{-1}X^Ty
  eps_hat       = y - X %*% beta_hat[i]               # \hat{\eps}     = y-X\hat{\beta}
  sigsqr_hat[i] = (t(eps_hat) %*% eps_hat)/(n-p)      # \hat{\sigma}^2 =\hat{\eps}^T\hat{\eps}/(n-p)
}
U = ((n-p)/sigsqr)*sigsqr_hat                         # \chi^2 verteilte Zufallsvariable


graphics.off()
dev.new()
par(
family      = "sans",
pty         = "s",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2.5,1,0),
xaxs        = "i",
yaxs        = "i",
xpd         = TRUE,
font.main   = 1,
cex         = 1,
cex.main    = 1.2)

# density
xlimits     = c(0,30)
ylimits     = c(0,.12)
u_min  = xlimits[1]
u_max  = xlimits[2]
u_res  = 1e5
u      = seq(u_min, u_max, len = u_res)
p_u    = dchisq(u,n-p)

# histogram
hist(
U,
col   = "gray90",
prob  = TRUE,
xlab  = TeX("$((n-1)/\\sigma^2)\\hat{\\sigma}^2$"),
ylab  = "",
xlim  = xlimits,
ylim  = ylimits,
main   = "")

# density
lines(
u,
p_u,
lwd   = 2,
col   = "darkorange")

# Speichern
dev.copy2pdf(
file        = file.path("7_Abbildungen/alm_7_sigsqr_hat_1_tut.pdf"),
width       = 7,
height      = 3.5)
```

\color{darkcyan}
\footnotesize
Visualisierung von $\chi^2(\frac{n-1}{\sigma^2}\hat{\sigma}^2;n-1)$ für $y \sim N(X\beta,\sigma^2 I_n)$ mit $\beta = \mu = 2$ und $\sigma^2=1$. Mit anderen Worten, wie sieht die Verteilung der skalierten Zufallvariable $\hat{\sigma^2}$, also $\frac{n-p}{\sigma}^2\hat{\sigma}^2$ aus, wenn wir aus der von uns angenommenen "wahren" Verteilung des Zufallsvektors $y \sim N(X\beta,\sigma^2 I_n)$ ganz viele Realisierungen generieren, (z.B. 10000 Realisierungen $y^{(1)},...,y^{(10000)}$), und für jede dieser Datensätze einen Varianzparameter schätzen ($\hat{\sigma}^{2(1)}, ..., \hat{\sigma}^{2(10000)}$). 

\center
\vspace{2mm}
\color{orange}
$\chi^2(\frac{n-p}{\sigma^2}\hat{\sigma}^2;n-1)$

```{r, echo = FALSE, out.width="70%"}
knitr::include_graphics("7_Abbildungen/alm_7_sigsqr_hat_1_tut.pdf")
```







# Frequentistische Schätzerverteilungen
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 5. Skizzieren Sie die WDFen von $t$-Zufallsvariablen mit $2$, $10$ und $30$ Freiheitsgraden.

\vspace{3mm}
\color{black}
\footnotesize

```{r, echo = F, eval = F}
library(latex2exp)
dev.new()                                                                        # new figure
fig     = par(                                                                   # figure parameters
            family     = "sans",                                                 # font family
            pty        = "m",                                                    # square plots
            bty        = "l",                                                    # plot box, o, l, 7, c, or ]
            lwd        = 1,                                                      # line width
            las        = 1,                                                      # 0: axis parallel, 1: horizontal, 2: axis perpendicular, 3: vertical
            mgp        = c(2,1,0),                                               # margin line in mex unit
            xaxs       = "i",                                                    # "internal" (tight) x-axis style
            yaxs       = "i",                                                    # "internal" (tight) y-axis style
            font.main  = 1,                                                      # title font type
            cex        = 1.1,
            cex.main   = 1.5                                                     # title  magnification factor
)

# t space
t_min   = -5                                                                     # minimum t-value
t_max   = 5                                                                      # maximum t-value
t_res   = 1e3                                                                    # t-space resolution
t       = seq(t_min,t_max, len = t_res)                                          # t-space

# parameters of interest
n       = c(2,10,30)                                                        # degrees of freedom


# plotting
matplot(t,
        matrix(c(dt(t,n[1]),
                 dt(t,n[2]),
                 dt(t,n[3])),
               ncol = 3),
        type         = "l",                                                      # line plot
        lty          = 1,                                                        # solid line
        lwd          = 2,                                                        # line width
        col          = c("gray10", "gray70", "gray90"),       # line colors
        ylim         = c(0,.4),                                                  # y-axis limits
        xlim         = c(t_min,t_max),                                           # x-axis limits
        ylab         = " ",                                                      # y-axis label
        xlab         = "t",                                                      # x-axis label
        main         = TeX("$\\T(t;n)$"))                                        # main title

legend( 2,                                                                       # x-ordinate
        .4,                                                                      # y-ordinate
        c("n = 2", "n = 10", "n = 30"),                        # legend text
        lty         = 1,                                                         # line type
        lwd         = 2,                                                         # line width
        col         =   c("gray10", "gray70", "gray90"),     # line colors
        bty         = "n",                                                       # no legend box
        cex         = 1.1,                                                       # character expansion (fontsize)
        y.intersp   = 1.6)                                                       # y-direction character spacing


dev.copy2pdf(                                                                    # export to PDF
    file   = file.path(getwd(), "7_Abbildungen", "alm_7_t_SKF5_wdf.pdf"),            # filename
    width  = 6,                                                                  # PDF width
    height = 5                                                                   # PDF height
)
```

\vfill
\vspace{2mm}
```{r, echo = FALSE, out.width="60%"}
knitr::include_graphics("7_Abbildungen/alm_7_t_SKF5_wdf.pdf")
```
\vspace{-3mm}
\footnotesize
\color{darkcyan}
Anmerkungen:

* \color{darkcyan}Die Verteilung ist um 0 symmetrisch
* Steigendes $n$ verschiebt Wahrscheinlichkeitsmasse aus den Ausläufen zum Zentrum





# Frequentistische Schätzerverteilungen
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 6. Skizzieren Sie die WDFen von nichtzentralen $t$-Zufallsvariablen mit Nichtzentralitätsparametern $0$,$5$ und $15$.

\vspace{3mm}
\color{black}
\footnotesize

```{r, echo = F, eval = F}
options(warn=-1)                                                                 # warning off
t_min     = -5                                                                   # Minimum T-Wert
t_max     = 30                                                                   # Maximum T-Wert
t_res     = 1e3                                                                  # T-Wert Auflösung
t         = seq(t_min, t_max, len = t_res)                                       # T-Raum
delta     = c(0,5,15)                                                            # Nichtzentralitätsparameter
n         = 30                                                            # Freiheitsgrade
p         = cbind(
            matrix(dt(t, n, delta[1]),nrow=length(t)),
            matrix(dt(t, n, delta[2]),nrow=length(t)),
            matrix(dt(t, n, delta[3]),nrow=length(t)))

# Visualisierung
dev.new()
graphics.off()
par(
family      = "sans",
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1.2)
matplot(
t,
p,
type        = "l",
lty         = 1,
col         = c("gray10", "gray50", "gray70"),
lwd         = 2,
xlab        = "T",
ylab        = "",
ylim        = c(0,.4),
main        = TeX("$t(T;\\delta,n)$"))
legend(
18,
.4,
c(TeX("$\\delta = 0 , n = 30$"),
  TeX("$\\delta = 5 , n = 30$"),
  TeX("$\\delta = 15, n = 30$")),
lty         = 1,
col         = c("gray10", "gray50", "gray70"),
lwd         = 2,
bty         = "n",
seg.len     = 1.75)
fdir        =  file.path(getwd(), "7_Abbildungen")
dev.copy2pdf(
file        = file.path(fdir, "alm_7_nichtzentrale_t_verteilung_SKF_6.pdf"),
width       = 7,
height      = 4.5)
```

```{r, echo = FALSE, out.width = "80%"}
knitr::include_graphics("7_Abbildungen/alm_7_nichtzentrale_t_verteilung_SKF_6.pdf")
```






# T-Statistiken
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 7. Geben Sie die Definition der T-Statistik wieder.
\vspace{3mm}
\color{black}

\footnotesize
\begin{definition}[T-Statistik]
Es sei
\begin{equation}
y = X\beta + \varepsilon \mbox{ mit } \varepsilon \sim N(0_n,\sigma^2I_n)
\end{equation}
das ALM in generativer Form. Weiterhin seien
\begin{equation}
\hat{\beta} := (X^TX)^{-1}X^Ty \mbox{ und } \hat{\sigma}^2 := \frac{(y - X\hat{\beta})^T(y - X\hat{\beta})}{n-p}
\end{equation}
die Betaparameter- und Varianzparameterschätzer, respektive. Dann ist für einen
\textit{Kontrastgewichtsvektor} $c \in \mathbb{R}^p$ die \textit{T-Statistik} definiert als
\begin{equation}
T := \frac{c^T\hat{\beta}}{\sqrt{\hat{\sigma}^2c^T(X^TX)^{-1}c}}.
\end{equation}
\end{definition}





# T-Statistiken
\vspace{3mm}
\setstretch{1}
\large
\color{darkblue} 8. Erläutern Sie die Definition der T-Statistik.
\vspace{3mm}
\color{black}
\footnotesize

\setstretch{1.5}
* Die T-Statistik hängt durch die Parameterschätzer $\hat{\beta}$ und $\hat{\sigma}^2$ von den Daten $y$ ab.
* Der Kontrastgewichtsvektor $c \in \mathbb{R}^p$ projiziert $\hat{\beta}$ auf einen Skalar $c^T\hat{\beta}$.
* Intuitiv quantifiziert die T-Statistik das Verhältnis von geschätzte Effektstärke zur geschätzten stichprobenumfangskalierten Datenvariabilität
\begin{align*}
T = \frac{\mbox{Geschätzte Effektstärke}}{\mbox{Geschätzte stichprobenumfangskalierte Datenvariabilität}}
\end{align*}
 und repräsentiert damit ein Signal-zu-Rauschen Verhältnis (signal-to-noise ratio).


